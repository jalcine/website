---
layout: post
title: "What's There to Build (Anymore)?"
date: 2014-03-20 08:38:47 EDT
categories:
  - thoughts
  - development
---

I've recently got a copy of this book called Hackers[^1] and so far, it's a
*very* interesting read for people like me (programmers who came after the
Last Hacker). I haven't read more than ten pages when I came upon the
realization that there isn't that much anymore to build. Yes, there's a
(partly disgusting) craze to build "the next Facebook" or the "Twitter for
babies" but that isn't something that requires thought. Like legitimate
turmoil, brain busting or work. Sure, there's developers writing code,
designers modelling and designing, sales selling and stuff, but who benefits?
If you're not a direct beneficiary, or rather if the people benefits from
your work way more than you do, that's **progress** in my book. Do we have
any of that anymore, in the computer science world? I might be speaking very
ignorantly since again, I haven't finished the book yet nor am I a super-duper
"rockstar", but the point's made.

> I do want to help, but 70% of the time I have absolutely *no idea* what 
> one might be referring to and I feel bad for that. It's no one's fault.

# Education

This is also an observation that I'm noting about technical literacy amongst
peers. I get scared when people ask if I have Google on my CPU. We're decently
far along this route that we shouldn't have people asking pseudo-questions
like that. It sucks because I do want to help, but 70% of the time I have
absolutely *no idea* what one might be referring to and I feel bad for that.
In the US, I remember hearing on the news that some high schools are
implementing computer literary as part of the curriculum. Awesome, but what
*exactly* are these people going to be teaching? Will they be taught to be
slaves to a particular product churned out by one company or would they be
informed on the aspects of a certain application and what pros and cons would
be worth investigating? Would security in computer use not only entail
installing anti-virus software but also following practices like perhaps
cryptographically securing content whose integrity they'd want to ensure to
its recipients? How about application installation practices and
permissions[^3]? Things like this could be put into a handbook or short
workshop similar to how health is taught for half a year in New York City
public high schools.

> Would they be telling students that Microsoft Word is the only known word 
> processing solution there is? Or that the only computer known to man is a Mac?

I would want fair education on topics here pertaining to computer usage 
and common application use but one could counteract with the lack of 
creationism being taught in public schools. Although the answer to that 
statement is simple[^2], it could be said for technology when it comes to 
spreading doctrines on the kind of computer and software one would use. The
one benefit out of this is mainly smarter consumers. Technology is shit
today when it comes to upgrading hardware and software largely in part due to
the mass not being properly educated on what they keep in their pocket and
bags every day. This practice is the same as grocery shopping and car
shopping; it'd make sense to learn about the thing you plan to buy if you hold
it to high esteem or value.

# The Web
Another thing that's starting to happen more and more is the lack of having
applications work properly **offline**. It's as if the aspect of not having
Internet is a daunting and almost baffling aspect of life. Personally, I
thought so a while ago. But these last few months, I haven't had a stable
Internet connection so the ability to do what I'd like to do without a network
connection is one I'd love to keep. It's one reason I moved this from 
Wordpress[^4] to a static weblog. Google, however, makes money on the Web
itself and its push for Web applications for everything really has consumed
consumer computing (i.e: word processing, e-mail checking, search). There was
a point in time when Google had a desktop search utility[^5] for Windows that
generated an index of files on your computer and mixed Google search results
with your queries. Talk about hits.

This is partly inevitable and as much as it seems that I don't like it; I'd
adopt the trend. It'd be easier once Internet access is freely available. I
think I'd rather pay for services I'd use on the Internet instead of paying
for the Internet itself. That seems to be the future trend with the lack of
Internet Neutrality and might be the only positive aspect of it, but I
digress.

# The Future
Now, looking forward, what can we expect? It's hard to say. Consumer
technology is becoming more and more part of the legislative process. This is
meant to prevent one company from controlling too much of a particular
"innovation" or industry but more harm is inevitable when big players fray
away from standards and build their own form of proprietary bullshit. The only
hopeful thing I see happening is the revitalization or maybe just the shock
that hardware is getting nowadays. Hardware tinkers tend to start off using
things like Adafruit's boards and learn how to solder but to properly build
something with granular control, the 3D printing wave would come into play.
Once 3D printing is as cheap as laptops get (or even cheaper), the act of
designing a PCB in a computer and printing it would be one to allow for anyone
to build their own tech. Imagine: you're in a store and you just want the best
laptop you can get your hands on. Synthesizing the parts necessary like the
motherboard and other components is a matter of pushing buttons in a display
glass. Companies could use their specifications and perhaps make
implementations that could be sold for individual use and hackers could work
and build a freely open piece of hardware. A day like that is when I feel
technology would be as ubiquitous as other freedoms we have today. Until then,
I'd be coding away.

[^1]: "Hackers: Heroes of the Computer Revolution" by Steven Levy, 2010, O'Reilly Media.
[^2]: The state **should** have no interest in religion and therefore isn't obligated or should ever feel compelled to teach religious doctrines as a equivalent to other secular fields.
[^3]: This would probably covering being more sharp about what permissions new applications would want to have on your devices. Mobile devices have a whole permission architecture that makes it easier to see what an application can be possibly do but on desktop machines, it's a bit tricky.
[^4]: Betcha didn't know that! It was about 3 years ago since I've made the transition.
[^5]: I think it's discontinued; but you probably could find an executable somewhere.
